# DEBUG MODE #
##############
# Has already computed margins fit (be careful, the process is quite slow for heavy files)
restart.marginsfit=FALSE
# Has already selected some storms the user is happy with
hasDeclusteredStorm=FALSE

# MODEL PARAMETRISATION #
#########################
# Threshold associated probability for margin transformation
p=0.01
# Margin count observations per year 
#margin.observation.per.year=1583  for arpera data
margin.observation.per.year=8766

## Margin declustering for local GPD fit
# Allow declustering
cmax=TRUE
# Consecutive below threhsold u to define another cluster
consecutivebelow=5

## Margin transformation algorithm (i.e. 1, 2, 3 or 4) to unit Frechet or GPD standard
# 1: If a value is below the threshold u, we use the empirical distribution below u ; otherwise we use the fitted GPD distribution
# 2: If at least one value goes above its local threshold u, any values of the spatial process is transformed thanks to its local GPD distribution. Otherwise we use the local empirical distribution.
# 3: Any values (below and above the threshold u) is transformed using the local empirical distribution.
# 4: Any values (below and above the threshold u) is transformed using the fitted parametric (GPD) distribution using the threshold u
margin.transformation.mode=4

# Reference location to control the uplift. 
# Either be both t0.ref.lon and t0.ref.lat values if gridded file or one ref.node value if not.
t0.ref.lon=NULL
t0.ref.lat=NULL
t0.ref.node=1719

## Computation mode of t0
# 1: t0 <- (1 + gamma*(b.tt0-b.t)/a)^(1/gamma) where b.tt0 is a given return value m.rlevel corresponding to the return period m.returnperiod (year)
# 2: t0 is computed relatively to the max of each storm i at reference location : max_i such that max_i = m.relevel corresponding to the return period m.returnperiod (year)
t0.mode=1
m.returnperiod=100

## Storm detection
# Reference (fixed) location to detect storms. Either be both ref.lon and ref.lat values if gridded file or one ref.node value if not.
has.fixed.reference=TRUE
ref.lon=NULL
ref.lat=NULL
ref.node=1719

# Set hyperslab(s) (e.g. rectangle areas) to detect storms
has.hyperslab.reference=FALSE
file.hyperslab.reference=../../inputs/hyperslabs/hyperslabs-storm-detection.csv

##	 Storm Declustering 
# (delta are given in time unit of input ncdf file)
delta.storm=48
rdelta.storm=12
nbr.storms=2

# NETCDF FILES #
#######################
# Temporary files relative to workdir
tmpnormalized=../../work/normalised-file.nc
tmpfitinfo=../../work/gpdfitsinfos.nc

# Path to the outputs directory relative to workdir
outdir=../../outputs

# Path to the inputs directory relative to workdir
#indir=../../inputs/arpera
indir=../../inputs/ww3

# Path to the input file relative to workdir
#file=../../inputs/arpera/wind-ARPERAREC.nc
file=../../inputs/ww3/megagol2015a-gol-cleaned.nc

# Path to work (temp) directory
workdirtmp=../../work

# Boolean to set if data is gridded or not
grid=FALSE

# Variable from NCDF file to analyse (e.g. "hs")
#var=UX10
var=hs

# Covariable from NCDF file to analyse (e.g. "dir"")
#covar=UX10
covar=th01

# GLOBAL ENVIRONMENT #
######################
# Environment to source to have local commands like ncks (nco)
env="source env.sh;"

# Define if it will use the parallel functions or not
parallel=TRUE

# Workdir
workdir=/Users/rchailan/Desktop/OnGoing/SpaceTimeExtreme/deHaan-sp/R/scripts
#workdir=/gpfs/users/rchailan/phd/R/SpaceTimeExtreme/deHaan-sp/R/scripts