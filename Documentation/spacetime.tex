\input{frontpage.tex}

{\bf Purpose of the document}\\ 
\smallskip
The present document is a personal notebook about Space-Time extreme modelling. In this document we would like to -- deeply -- describe the semi-parametric methods referred in (Caires, 2011)\REF and provide a framework to generalise them. The final goal of the study being to create Space-time extreme processes, further used as inputs fields of other numerical models (e.g., submersion phenomenon).

\bigskip

%--------------------------------------------------------------------------
%--------------------------------------------------------------------------
\section{Context}
(Caires, 2011) work on similar challenges to the one of my PhD thesis. They aim to construct methods to better represent extreme events. Their final goal is also to be able to created representative extreme-events  -- with long return periods -- to assess coastal hazards in such extreme condition. For instance such fields may force physical coastal models (e.g., dykes fatigue).\\
In this context they ask two expert of extreme value modelling : Pr.~Laurens de Haan and Pr.~Richard Smith to help them. Both professors respond to Dr.Sofia Caires's request. (Caires, 2011) present their advices and the proposed methods. Later (Groeneweg, 2012) present their implementation -- which remain slightly modified -- of the proposed methods for a wind data set other the Netherlands.\\

In the present document we synthesize the expert's approaches plus their implementation in (Groeneweg, 2012)\REF. We also provide details on specific key points whether from technical point of view or to ease the overall comprehension. Finally we propose our so-called generalised form of semi-parametric method, as adaptation of the former ones.\\

{\bfseries N.B.:} Either (Groeneweg, 2012) or our generalised proposition remain adaptations of the advices from Pr.~de Haan and Pr.~Smith. Therefore we chose to present both methods proposed by those experts in separate subsections. The adaptations made in (Groeneweg, 2012) or in our generalised proposition respect the following colours rules:
\begin{itemize}
\item  {\color{blue} Any adaptation of (Groeneweg, 2012) is juxtaposed in blue.}
\item  {\color{red} Any adaptation of our generalised proposition is juxtaposed in red.}
\end{itemize}

%--------------------------------------------------------------------------
%--------------------------------------------------------------------------
\section{Space-time extreme processes: semi-parametric methods}
%--------------------------------------------------------------------------
\subsection{Method advised by Pr.~Laurens de Haan}

Technically speaking, the overall method consists in detecting storms in a data set from a reference location and then uplifting all the values regarding their marginal distribution. To do so, margins transformation are needed from initial distribution to a standard distribution.
Pr.~de Haan uses a standard Pareto transformation, i.e. $\frac{1}{\overline{G}(X)}$ where $G$ is a GPD distribution.\\
The global scheme is then to transform data from the entire process when the reference location excesses a threshold $\mu_{r}$ up to a higher threshold $\mu_{r_0}$, i.e. $\mu_{r} \leq \mu_{r_0}$ .\\

Pr.~de Haan mathematically justifies his approach in (Caires, 2011) from univariate process to spatial process. However, even if an indication is given for a space-time process, several questions arise.\\
Indeed, Pr. de Haan proposes to apply the spatial procedure, but he recommends a de-clustering step to select storms. His advice is when an excess is detected at a time $t$, a storm is selected by taking all values in $[ t-\mathcal{\delta}; t+\mathcal{\delta}]$. $\delta$ being arbitrary chosen.\\
However in that case does the mathematical justification still hold ? In particular Pr.~de Haan does not explicit how the value are locally transformed in that case.\\
{\color{blue} (Groeneweg, 2012) present a margin transformation using -- as the local GPD fit for any values of a detected storm. At the end of the paper they also \textit{augment the distribution $G$ by the empirical distribution below the selected threshold $u$.}}\\
{\color{red} We state that there are many ways to proceed in that case. We identified 4 ways to transform the margins considering any values at a time $t$ and location $s$ of the data-set.
\begin{enumerate}
\item A - If a value is below the threshold $\mu_s$, we use the margin empirical distribution below $\mu_s$ ; otherwise we use the margin fitted GPD distribution.
\item B - If at least one value goes above its local threshold $\mu_s$, any values of the spatial process is transformed thanks to its margin GPD distribution. Otherwise we use the local empirical distribution.
\item C - Any values (below and above the threshold $\mu_s$) is transformed using the margin empirical distribution.
\item D - Any values (below and above the threshold $\mu_s$) is transformed using the margin fitted parametric (GPD) distribution.
\end{enumerate}
}
Those issues were not raised by Pr.~de Haan since in his advice the time evolution were not considered\footnote{Or his assumption is that his justification holds in the space-time framework, i.e. transform the data like in (Groeneweg, 2012) without augmentation of local empirical distribution}.\\

{\bfseries Step by step:}
\begin{enumerate}
\item Start with a data-set $X(s,t)$ where $s \in \mathcal{S}$ is the location index and $t \in \mathcal{T}$ is the time index.
\item Given a local threshold $u_s$, apply the POT method to estimate the margin GPD parameters, i.e. the scale parameter $\hat{\sigma}_s$ and the shape parameter $\hat{\gamma}_s$. {\color{red} The POT methods should be carried with attention to the de-clustering of the margin time-series. This is essential to reach the independence condition required by the POT procedure}.
\item Given a reference location $s_r$, select storms\footnote{here we assume we deal with space-time processes, therefore we need the de-cluster step later given as indications in (Caires,2011) by Pr.~de Haan.}. We assume the following scheme : 
\begin{algorithm}
	\caption{Storm selection de Haan's approach}
	\label{algo-stormselection-dehaan}
	\begin{algorithmic}
	\State $i \gets 0$
	\State $X' \gets X$ with all margin rescaled as $X'(s) = \frac{X-\mu_{s}}{\hat{\sigma}_{s}}$
	\While{$\exists \: x, \: x \in X'(s_r,t) \quad \text{s.t.} \quad  x-\mu_{s_r} > 0$}
	\State $t_i \gets$ Find time for the highest remaining peak at location of reference $s_r$ from $X'(s_r,t)$
	\State $X^{(1)}_i \gets [X(\cdotp,t_i-\delta); X(\cdotp,t_i+\delta) ]$
	\State $X'(\cdotp,t) \gets X'(\cdotp,t) \notin \left[ X'(\cdotp,t_i-\delta-\zeta); X'(\cdotp,t_i+\delta+\zeta) \right] $ 
	\State $i \gets i+1$
	\EndWhile
	\end{algorithmic}
\end{algorithm}

This algorithm of selection of storm is handy but does not follow the justification of Pr.~de Haan. This comes from the selection of a reference location. However the expert himself states that to select any peak from $X(s_r,t)$ instead of $X(\cdotp,t)$ is still correct but consider only a subset of the actual storms. An other alternative is between the both: {\color{red} to select the peak inside a subset of locations, i.e. $X(s_l,t)$ where $l \in \{1,\ldots,p\} $, such that $s_l \subset \mathcal{S}$.}
\item  Determine a constant $t_0$ such that
	\begin{equation}
	\label{eq:t0}
	t_0 = \left( 1+ \hat{\gamma}_{s_r}  \frac{\mu_{r_0} - \mu_{r}}{\hat{\sigma}_{r}} \right)^{\frac{1}{\hat{\gamma}_{s_r}}},
	\end{equation}
where $\mu_{r_0}$ is the $m$-year return value at $s_r$ and $m$ the return period, e.g, 100. The return period of the overall uplifted storm will be associated to this return value. See Section~\ref{sec:t0lambdam}.
\item Transform{\footnote{Pareto transformation.}} $\{X^{(1)}_i\}$ by:
	\begin{equation}
	\label{eq:transfogpdtopareto}
	X^{(2)}_i(s) = t_0 \left( 1 + \hat{\gamma}_{s} \frac{X^{(1)}_i(s) - \mu_{s}}{\hat{\sigma}_s} \right)^{\frac{1}{\hat{\gamma}_s}},
	\end{equation}
and then transform back to the origin scale with
	\begin{equation}
	\label{eq:transfoparetoorigin}
	X^{(3)}_i(s) = \frac{\left(X^{(2)}_i(s) -1 \right)^{\hat{\gamma}_s}}{\hat{\gamma}_s} + \mu_{s} .
	\end{equation}
\end{enumerate}

Equation~\ref{eq:transfogpdtopareto} -- consequently Equation~\ref{eq:transfoparetoorigin} -- are \note{only?} valid in the justification of Pr.~de Haan for spatial processes. For higher dimension processes, as presented before, we should adapt these transformations. 

\begin{itemize}
\item A - The initial marginal distribution $G$ must be defined as 
\begin{align*}
G(x) := \left\{
\begin{array}{rl}
  \frac{i_x}{m+1} , \quad &\text{if} \:\: x-\mu < 0 \\
  1 - \left( 1 + \gamma \frac{x - \mu}{{\sigma}} \right)^{-\frac{1}{\gamma}} , \quad &\text{if} \:\: x-\mu \geq 0 
\end{array}
\right.
\end{align*}
In this marginal representation, $m$ is the number of observations and $i_x$ the rank of the observation (empirical distribution).\\
Hence, if $(x-\mu < 0)$, the transformation to Pareto distribution becomes
\begin{align*}
\frac{1}{\overline{G}(x)} = \frac{1}{1-\frac{i_x}{m+1}} = \frac{m+1}{m+1-i_x},
\end{align*}
then
\begin{align*}
x^{(2)}_{s,t} = t_0 \frac{m+1}{m+1-i_x},
\end{align*}
and
\begin{align*}
x^{(3)}_{s,t} &= 1 - \frac{1}{x^{(2)}_{s,t}} \\
			&= 1 - \frac{m+1-i}{t_0 \left( m+1 \right) }.
\end{align*}

If  $(x-\mu \geq 0)$, (\ref{eq:transfogpdtopareto}) and (\ref{eq:transfoparetoorigin}) are still valid.

\item B - 
\begin{align*}
G(x) := \left\{
\begin{array}{rl}
  \frac{i_x}{m+1} , \quad &\text{If $\forall \: s \in \mathcal{S},$ $(x_{s,t} - \mu_{s} < 0)$} \\
  1 - \left( 1 + \gamma \frac{x - \mu}{{\sigma}} \right)^{-\frac{1}{\gamma}} , \quad &\text{If $\exists \: s \in \mathcal{S}$ such that $(x_{s,t} - \mu_{s} \geq 0)$}. 
\end{array}
\right.
\end{align*}
\item C - \begin{align*}
G(x) := \frac{i_x}{m+1}
\end{align*}
\item D - There is no need to change the presented transformations (\ref{eq:transfogpdtopareto}) and (\ref{eq:transfoparetoorigin}).
\end{itemize}

%--------------------------------------------------------------------------
\subsection{Method advised by Pr.~Richard Smith}
Pr.~Smith's approach is very similar to the one proposed by Pr.~de Haan. However Pr.~Smith's approach rests on a margin transformation to a Frechet standard distribution, i.e. $\frac{-1}{\log(1-\overline{G}(X))}$ where $G$ is a GEV distribution. Hence the transformation of the margin time-series is given by
\begin{equation}
\label{eq:pointprocess}
	Y(s) = \left( 1 + \hat{\xi}_{s} \frac{X(s) - \mu_{s} }{\hat{\sigma}_s} \right)^{1/\hat{\xi}_s},
\end{equation}
where $\hat{\sigma}_s$ and $\hat{\xi}_s$ are the parameters of the estimated GEV distribution at location $s \in \mathcal{S}$. The parameters are estimated thanks to the point process characterization of extremes. See Chapter~7 of (Coles, 2001) for details on that approach.\\

This transformation is the first step of the procedure\footnote{In his advice, Pr.~Smith does not precise if the distribution is augmented from the empirical distribution for the values below the local threshold $\mu$ used in the point process method. It rather seems that all data is transformed, see (Caires, 2011) p17 of Smith's Advice.}.

Once the data is transformed, use a de-clustering algorithm to select space-time processes identified as storms. The algorithm is the same as Algorithm~\ref{algo-stormselection-dehaan} but 1) Pr.~Smith works on transformed data directly and 2) peaks are detected over all locations. The later is the main difference from Pr.de Haan's approach.

\begin{algorithm}
	\caption{Storm selection Smith's approach.}
	\label{algo-stormselection-smith}
	\begin{algorithmic}
	\State $i \gets 0$, $\delta \gets \text{Cst}$, $\zeta \gets \text{Cst}$
	\State $Y \gets X$ with all margin transformed to Fr\'echet distribution $Y(s) = -\frac{1}{\log{G(X(s))}}$
	\While{$\exists \: x, \: x \in Y(s_r,t) \quad \text{s.t.} \quad  x-\mu_{s_r} > 0$}
	\State $t_i \gets$ Find time for $\max{ Y(\cdotp,\cdotp)}$
	\State $Y_i \gets [Y(\cdotp,t_i-\delta); Y(\cdotp,t_i+\delta) ]$
	\State $Y(\cdotp,t) \gets Y(\cdotp,t) \notin \left[ Y(\cdotp,t_i-\delta-\zeta); Y(\cdotp,t_i+\delta+\zeta) \right] $ 
	\State $i \gets i+1$
	\EndWhile
	\end{algorithmic}
\end{algorithm}

Then take the within-storm maxima of the top-N storms identified $Y_i$ and denote them as
\begin{align*}
Y^*_1 > Y^*_2 > \ldots > Y^*_N.
\end{align*}

Following the equations presented in Section~\ref{sec:frechetassumption} we can state that 
\begin{equation}
\label{eq:frechetassumtion}
P(Y^* > y \: | \: Y^* > u) \sim \left( \frac{y}{u} \right) ^{-\frac{1}{\alpha}},
\end{equation}
where $\alpha = \frac{1}{\xi}$. \\
If we assume (\ref{eq:frechetassumtion}) as exact, from the well-known Hill estimator the maximum likelihood estimator of $\alpha$ is
\begin{equation}
\label{eq:alpha}
\hat{\alpha} = \frac{(N - 1)} { \sum\limits_{i=1}^{N-1} \log{\frac{Y^*_i}{u}}}.
\end{equation}
Let $\lambda$ denote the rate of exceedances of the threshold, i.e. the number of storms per year. A natural estimator of $\lambda$ is 
\begin{equation}
\label{eq:lambda}
\hat{\lambda} = \frac{N-1}{N_{tot}},
\end{equation}
with $N_{tot}$ the total number of years of data.
Combining (\ref{eq:lambda}) and (\ref{eq:alpha}) the natural estimator of the $M$-year return value is
\begin{align*}
P(Y^* > y_m \: | \: Y^* > u) \: \hat{\lambda} &= \frac{1}{M} \\
\hat{\lambda} \left( \frac{y}{u} \right) ^{-\frac{1}{\alpha}} &= \frac{1}{M} \\
\hat{y}_m &= u \left( M \hat{\lambda} \right)^\frac{1}{\hat{\alpha}}.
\end{align*}
{\color{red} Pr.~Smith indicates that if a reference site is used to detect the storms, the (\ref{eq:lambda}) and (\ref{eq:alpha}) should be re-written and therefore the estimation of the $M$-year return value change in its definition.}

Finally to generate the space-time distribution for a hypothetical $2000$-year return event, Pr.~Smith proposes also a scaling approach. From the last relation $\hat{y}_{2000} = u \left( 2000 \hat{\lambda} \right)^\frac{1}{\hat{\alpha}}$ is an estimate for the cluster maximum to a $2000$-year event.\\
Justifying that such event can be represented by a single realization of a max-stable process, Pr.~Smith states that we get events of different severity by multiplying by different constants. The following algorithm is proposed to construct such events:

\begin{algorithm}
	\caption{Storm uplift Smith's approach.}
	\label{algo-stormuplift-smith}
	\begin{algorithmic}
	\State Randomly choose one of the top $N$ clusters generated from Algorithm \ref{algo-stormselection-smith}.
	\State Reset the cluster maximum to $\hat{y}_{2000}$.
	\State Rescale all the other members of the cluster proportionally -- if the cluster maximum is $Y^*_i$ then every member of the cluster is multiplied by $\hat{y}_{2000}/Y^*_i$.
	\State Invert the original marginal transformation -- i.e. the inverse of Equation \ref{eq:pointprocess}.
	\end{algorithmic}
\end{algorithm}

%--------------------------------------------------------------------------
\subsection{Proofs and details of some relations}
\subsubsection{Transformation from GPD to Pareto}
\label{sec:transfoGPD2Pareto}
\begin{align*}
\frac{1}{\overline{G}(Y)} &= \frac{1}{1-\left[1 - \left( 1 + \gamma y   \right)^{-\frac{1}{\gamma}} \right]} \\
						  &= \left( 1 + \gamma y   \right)^{\frac{1}{\gamma}}\\
						  &= \left( 1 + \gamma  \frac{x - \nu}{\psi}   \right)^{\frac{1}{\gamma}} ,
\end{align*} where $Y$ follows a GPD distribution and $\nu$, $\psi$, $\gamma$ are respectively the determined threshold, the scale and the shape parameters of the GPD.\note{peut etre je vais echanger les notations pour etre coeherent avec les sections pr\'ec\'edente.} 

%--------------------------------------------------------------------------
\subsubsection{Transformation from GEV to Frechet}
\label{sec:transfoGEV2Frechet}
\begin{align*}
-\frac{1}{\log(G(X))} &= - \frac{1}{\log \left( \exp{-\left[ 1+ \xi \left(\frac{x-\mu}{\sigma}\right)\right]^{-\frac{1}{\xi}}} \right)} \\
					  &= - \frac{1}{-\left[ 1+ \xi \left(\frac{x-\mu}{\sigma}\right)\right]^{-\frac{1}{\xi}} } \\
					  &= -1 \times - \left[ 1+ \xi \left(\frac{x-\mu}{\sigma}\right)\right]^{\frac{1}{\xi}}  \\
					  &= \left[ 1+ \xi \left(\frac{x-\mu}{\sigma}\right)\right]^{\frac{1}{\xi}}, 
\end{align*}
where $X$ follows a GEV distribution and $\mu$, $\sigma$, $\xi$ are respectively the location, the scale and the shape parameters of the GEV.
%--------------------------------------------------------------------------
\subsubsection{Equivalence between transformation to Pareto and to Frechet}
\label{sec:equivalenceParetoFrechet}
Equivalence from transformation Fr\'echet to transformation Pareto. 
\begin{align*}
-\frac{1}{\log(G(X))} = - \frac{1}{\log(1-\overline{G}(X))}  \overset{\text{d.l}}= - \frac{1}{- \overline{G}(X)} = \frac{1}{\overline{G}(X)},
\end{align*}
since according to Taylor's development if $X$ is big : $1-\overline{G}(X) \rightarrow 0$, then  $\log(1-\overline{G}(X)) = - \overline{G}(X)$.
%--------------------------------------------------------------------------
\subsubsection{Why \textit{t0 equal to lambda m}}
\label{sec:t0lambdam}
Pr.~de Haan propose to define the constant $t0$ by the Equation~\ref{eq:t0} that we recall below.
\begin{align*}
t_0 = \left( 1+ \hat{\gamma}_{s_r}  \frac{\mu_{r_0} - \mu_{r}}{\hat{\sigma}_{r}} \right)^{\frac{1}{\hat{\gamma}_{s_r}}},
\end{align*}
where $\mu_{r_0}$ is the $m$-year return value at $s_r$ and $m$ the return period, e.g, 100.
(Caires, 2011) also state that 
\begin{align*}
t_0=\lambda_{s_r}m
\end{align*} 
if one is interested in the $m$-year storm according to the definition of Pr.~de Haan. In that relation $\lambda$ is the mean number of exceedances of $\mu_{r}$ per year. Since by definition
\begin{equation}
\label{eq:zm}
 z_m = \mu_r + \frac{{\hat{\sigma}_{s_r}}}{\hat{\gamma}_{s_r}} \left\{ \left( \lambda_{s_r} m \right) ^{\hat{\gamma}_{s_r}} - 1 \right\}
\end{equation}
is the return value of the return period $m$,
the proof of the former relation is found by replacing (\ref{eq:t0}) into (\ref{eq:zm})
\begin{align*}
t_0 &= \left(1+ \hat{\gamma}_{s_r} \frac{ \mu_{s_r} + \frac{{\hat{\sigma}_{s_r}}}{\hat{\gamma}_{s_r}} \left\{ \left( \lambda_{s_r} m \right) ^{\hat{\gamma}_{s_r}} - 1 \right\} - \mu_{s_r}}{\hat{\sigma}_{s_r}}  \right)^{\frac{1}{\hat{\gamma}_{s_r}}}\\
	&= \left(  \frac{\hat{\sigma}_{s_r} + \hat{\gamma}_{s_r} \frac{{\hat{\sigma}_{s_r}}}{\hat{\gamma}_{s_r}} \left\{ \left( \lambda_{s_r} m \right) ^{\hat{\gamma}_{s_r}} - 1 \right\}  }{\hat{\sigma}_{s_r}} \right)^{\frac{1}{\hat{\gamma}_{s_r}}}\\
	&= \left( \frac{\hat{\sigma}_{s_r} \left( \lambda_{s_r} m \right) ^{\hat{\gamma}_{s_r}} }{\hat{\sigma}_{s_r}} \right)^{\frac{1}{\hat{\gamma}_{s_r}}}\\
 	&= \lambda_{s_r}m \quad\quad.
\end{align*}
%--------------------------------------------------------------------------
\subsubsection{How and why find a \textit{t0i}}
\label{sec:t0i}
{\color{blue} (Groeneweg, 2012) adapt the determination of the amplifier coefficient from $t0$ to $t0_i$. This is to compare the uplifted processes constructed by the two methods independently.
In that case, $t0_i$ is determined by the following relation :\\
Lets $T$ be a margin transformation, $T(X)=\left( 1 + \hat{\gamma}_{s_r} \frac{X-\mu_{s_r}}{\hat{\sigma}_{s_r}} \right)^{\frac{1}{\hat{\gamma}_{s_r}}},$\\
then
\begin{align*}
\label{eq:t0i}
T^{-1} \left( t_{0_i} T(X_i) \right) &= z_m\footnote{$z_m$ is the targeted return value corresponding to the maxima of $X^3_{i}$}\\
t_{0_i} T(X_i)						 &= T(z_m)\\
t_{0_i} 							 &= \frac{T(z_m)}{T(X_i)} = \frac{\left( 1 + \hat{\gamma}_{s_r} \frac{z_m-\mu_{s_r}}{\hat{\sigma}_{s_r}} \right)^{\frac{1}{\hat{\gamma}_{s_r}}}}{\left( 1 + \hat{\gamma}_{s_r} \frac{X_1-\mu_{s_r}}{\hat{\sigma}_{s_r}} \right)^{\frac{1}{\hat{\gamma}_{s_r}}}}\\
t_{0_i} 							 &=  \left( \frac{ {z_m + \frac{\hat{\sigma}_{s_r}}{\hat{\gamma}_{s_r}} - \mu_{s_r}}} {{X_i + \frac{\hat{\sigma}_{s_r}}{\hat{\gamma}_{s_r}} - \mu_{s_r}}}  \right)^{\frac{1}{\hat{\gamma}_{s_r}}}
\end{align*}
}
In this relation, $X_i$ is the within-maxima of the storm $X^{(1)}_i(\cdotp,\cdotp)$. The consequence is that the within-maxima of the transformed storm $X^{(3)}_i(\cdotp,\cdotp)$ will be equal to the return value $z_m$ which is directly comparable in the sense of the Pr.~Smith approach.
%--------------------------------------------------------------------------
\subsubsection{Fr\'echet assumption (high values)}
\label{sec:frechetassumption}
By definition from the semi representation of Fr\'echet distribution we have
\begin{align*}
\overline{F}(x) = x^{-\frac{1}{\alpha}}\log{(x)}.
\end{align*}
Therefore we can show
\begin{align*}
\frac{\overline{F}(tu)}{\overline{F}(u)} &= \frac{ (tu)^{-\frac{1}{\alpha}}\log{(tu)} } {(u)^{-\frac{1}{\alpha}}\log{(u)} } = t^{-\frac{1}{\alpha}} \log{(tu - u)} \longrightarrow t^{-\frac{1}{\alpha}}.
\end{align*}
Hence
\begin{align*}
\overline{F}(tu) \sim \overline{F}(u) t^{-\frac{1}{\alpha}}.
\end{align*}
By setting $t=\frac{y}{u}$ we obtain
\begin{align*}
\overline{F}\left(\frac{y}{u}\right) \sim \overline{F}(u) \left(\frac{y}{u}\right)^{-\frac{1}{\alpha}}.
\end{align*} 
hence
\begin{align*}
P(Y > y \: | \: Y > u) = \frac{P(Y > y)}{P(Y > u)} = \frac{\overline{F}(y)}{\overline{F}(u)} = \left( \frac{y}{u} \right) ^{-\frac{1}{\alpha}},
\end{align*}
where $\alpha = \frac{1}{\xi}$.


%--------------------------------------------------------------------------
%--------------------------------------------------------------------------
\section{Generalised method}



%--------------------------------------------------------------------------
%--------------------------------------------------------------------------
\section{Perspectives}
As written in (Caires, 2011), one perspective is to compare such semi-parametric constructed extreme processes to the one that we would obtain with a full parametric approach, whether using max-stable space-time model (with an inference considering the excesses over threshold like in (Huser, 2014)) or using real GPD processes.\\
An other perspective is to work on the detection of the storm, especially by adding co-variables in the threshold evolution through time and space. 

\input{endpage.tex}